
# rboles de decisi贸n

## Bases

![[Pasted image 20211109172400.png]]

Los conjuntos nos permiten "votar" por la respuesta correcta.

6 谩rboles predicen 1;
3 谩rboles preciden 0;

Respuesta final: 1

## Par谩metros
N煤mero de 谩rboles: m谩s 谩rboles menor la variaci贸n, pero m谩s c贸mputo

Max features: El n煤mero de features usados para partir (split)

Max depth: El n煤mero de niveles del 谩rbol de decisici贸n

N$_s$$_p$$_l$$_i$$_t$ = Min samples split: N煤mero de data points que un nodo debe tener antes de dividirse.

n$_m$$_i$$_n$ = Min samples leaf: El m铆nimo n煤mero de muestras requeridas para estar en una hoja (leaf).

## Funci贸n de coste y regla de actualizaci贸n

Funci贸n de coste: Para un feature seleccionado encuentra el mejor split-point (punto de separaci贸n) y separa los datos en dos nodos m谩s peque帽os.

Regla de actualizaci贸n: Si el nodo hoja tiene m谩s de n$_m$$_i$$_n$ puntos de datos, repite la funci贸n de coste, sino para.

## Rendimiento
 Se pueden usar m茅tricas de clasificaci贸n o regresi贸n para evaluar qu茅 tan bueno es el modelo.
 
 Para clasificaci贸n se puede usa la matriz de confunci贸n de [[regresion logistica]]  mientras que para regresi贸n (predicci贸n) se puede usar MSE / R$^2$
 
 ## Repaso: ingredientes de 谩rbol de decisi贸n
 - Proceso de decisi贸n: De un subset de features aleatorios de tus datos elige un feature. Divide tus datos.
 - Funci贸n de error/coste: Usando Gini o criterio de entrop铆a para encontrar el mejor umbral para dividir tus datos.
 - Regla de actualizaci贸n:  Si los nodos hoja no tienen n$_m$$_i$$_n$ puntos de datos, repite el proceso.

Further reading [here](https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/#:~:text=A%20random%20forest%20is%20a%20machine%20learning%20technique%20that's%20used,consists%20of%20many%20decision%20trees.).